{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d78afe9",
   "metadata": {},
   "source": [
    "## Image Comparison Using Perceptual Hashing and Nearest Neighbors\n",
    "This notebook describes a personal project on strategies for image comparisons. 3 methods are used to find matching images between two folders (referred to as \"target\" folder and \"reference\" folder)\n",
    "\n",
    "1) Perceptual hashing alone (Hamming distance = 0) <br>\n",
    "2) Matching names (No hashing, just unique image names) <br>\n",
    "3) Nearest Neighbors (Hamming distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import csv\n",
    "from annoy import AnnoyIndex\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all image files in the \"target\" folder and adding to a list\n",
    "files_target = []\n",
    "files_target.extend(glob.glob(glob.escape(r'C:\\Users\\dramadas\\target1a') + '/**/images/**/*', recursive=True))\n",
    "files_target.extend(glob.glob(glob.escape(r'C:\\Users\\dramadas\\target1b') + '/**/images/**/*', recursive=True))\n",
    "print(*files_target, sep= \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19285f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all image files in the \"reference\" folder and adding to a list\n",
    "files_reference = []\n",
    "ref_dir = 'C:\\Users\\dramadas\\reference'\n",
    "#Need to esacpe special chars\n",
    "files_reference.extend(glob.glob(glob.escape(ref_dir) + '/**/*', recursive=True))\n",
    "print(*files_reference, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d065f2c",
   "metadata": {},
   "source": [
    "### 1) The following code will find exact matches, i.e. Hamming distance = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede55b73",
   "metadata": {},
   "source": [
    "This method loops through each image in Reference folder and finds matches in target folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dict of hashes for target images for easy comparison later\n",
    "target_dict = {}\n",
    "for target_image in files_target:\n",
    "    try:\n",
    "        img = Image.open(target_image)\n",
    "        img_hash = imagehash.phash(img)\n",
    "        #print(img_hash)\n",
    "        target_dict[img_hash] = target_image\n",
    "        img.close()\n",
    "    except OSError as error:\n",
    "        print(\"Error: \", target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b167e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through reference images and check if exists in target dict:\n",
    "with open('results_reference.csv', 'w', newline = '') as file:\n",
    "    writer = csv.writer(file)\n",
    "    headings = ['Image directory', 'Matching Image', 'Result', 'Size']\n",
    "    writer.writerow(headings)\n",
    "    \n",
    "    for ref_image in files_reference:\n",
    "        try:\n",
    "            img1 = Image.open(ref_image)\n",
    "            img1_hash = imagehash.phash(img1)\n",
    "            if img1_hash in target_dict:\n",
    "                print(\"Success\", ref_image)\n",
    "                writer.writerow([ref_image, target_dict[img1_hash], 'Pass', img1.size])\n",
    "            else:\n",
    "                writer.writerow([ref_image, 'NA', 'Fail', img1.size])\n",
    "            img1.close()\n",
    "        except OSError as error:\n",
    "            print(\"Error:\", ref_image)\n",
    "            writer.writerow([ref_image, 'NA', 'Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd330e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For debug only, if need to find files of a certain extension\n",
    "# for i in files_reference:\n",
    "#     if i.endswith('.tiff'):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972201a",
   "metadata": {},
   "source": [
    "### 2) Next, we try to find matching images based on their unique names\n",
    "This method was viable due to the unique naming of images within the reference and target folders. It is quick but has limitations. It requires post-processing and some manual filtering of the resulting csv. <br>\n",
    "In future, this method can be updated to match only if one unique name exists in target folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each file in target, store the file name in a dict\n",
    "target_name_dict = {}\n",
    "for target_image in files_target:\n",
    "    img1_name = os.path.basename(target_image)\n",
    "    target_name_dict[img1_name] = target_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f745947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this only works for unique names currently\n",
    "with open('results_reference_names.csv', 'w', newline = '') as file:\n",
    "    writer = csv.writer(file)\n",
    "    headings = ['Image directory', 'Matching Name']\n",
    "    writer.writerow(headings)\n",
    "    \n",
    "    for ref_image in files_reference:\n",
    "        try:\n",
    "            img1 = Image.open(ref_image)\n",
    "            img1_hash = imagehash.phash(img1)\n",
    "            if img1_hash not in target_dict:\n",
    "                img1_name = os.path.basename(ref_image)\n",
    "                # comparing names only\n",
    "                if img1_name in target_name_dict:\n",
    "                    print(img1_name)\n",
    "                    print(target_name_dict[img1_name])\n",
    "                    writer.writerow([ref_image, target_name_dict[img1_name]])\n",
    "                else:\n",
    "                    writer.writerow([ref_image, 'Fail'])\n",
    "            img1.close()\n",
    "        except OSError as error:\n",
    "            writer.writerow([ref_image, 'Error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93981efb",
   "metadata": {},
   "source": [
    "### 3) Finally, attempt to find matches using Nearest Neighbors\n",
    "\n",
    "This method uses Annoy to create a forest to find nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the remaining Failures (all Passes and Errors have been removed)\n",
    "df_remaining = pd.read_csv('results_reference_consolidated.csv') #this file has been manually filtered and created from steps above\n",
    "df_remaining = df_remaining[df_remaining[\"Result\"] == \"Fail\"]\n",
    "df_remaining[\"Result\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of the remaining failures\n",
    "ref_remaining = df_remaining[\"Image directory\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16881b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Annoy to create a forest for nearest neighbors\n",
    "vec_length = 64\n",
    "nn_dict = {}\n",
    "for count, f in enumerate(files_target):\n",
    "    img = Image.open(f)\n",
    "    img_hash = imagehash.phash(img)\n",
    "    hash_array = img_hash.hash.astype('int').flatten();\n",
    "    nn_dict[count] = hash_array\n",
    "    #Need to know indexes to know where to store the next image\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe8349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Try using hamming distance instead, find nearest neighbors\n",
    "num_trees = 200\n",
    "num_neighbors = 5 #one of these will be the searched reference image\n",
    "\n",
    "with open('results_reference_hamming.csv', 'w', newline = '') as file:\n",
    "    writer = csv.writer(file)\n",
    "    headings = ['Image directory', 'Nearest Neighbors 1', 'Hamming Distances']\n",
    "    writer.writerow(headings)\n",
    "    \n",
    "    for ref_image in ref_remaining:\n",
    "        print(ref_image)\n",
    "        try:\n",
    "            img1 = Image.open(ref_image)\n",
    "            img1_hash = imagehash.phash(img1)\n",
    "            \n",
    "            hash_array = img1_hash.hash.astype('int').flatten();\n",
    "            #This index is hardcoded to be the next index after all the target images\n",
    "            nn_dict[4641] = hash_array\n",
    "            #Using annoy to find nearest hamming distances\n",
    "            t = AnnoyIndex(vec_length, \"hamming\")\n",
    "            for key, value in nn_dict.items():\n",
    "                t.add_item(key,value)\n",
    "            t.build(num_trees)\n",
    "            #Passing the hardcoded index in\n",
    "            neighbors = t.get_nns_by_item(4641, num_neighbors, include_distances = True)\n",
    "            print(files_target[neighbors[0][1]])\n",
    "            print(\"Closest distance: \", neighbors[1][1])\n",
    "            writer.writerow([ref_image, files_target[neighbors[0][1]], neighbors[1][1]])\n",
    "            img1.close()\n",
    "        except OSError as error:\n",
    "            writer.writerow([ref_image, 'NA', 'Error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb9609",
   "metadata": {},
   "source": [
    "### This section below is to filter/merge matches by Hamming distance and can be run independently of code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dfd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge 2.0 Hamming distances into consolidated excel\n",
    "df_consolidated = pd.read_csv('results_reference_consolidated.csv')\n",
    "df_ham = pd.read_csv('results_reference_hamming.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98228e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = df_ham[df_ham[\"Hamming Distances\"] == 2.0] # Lower values indicate closer matches.\n",
    "df_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb28dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_merged = pd.merge(df_consolidated, df_ham, how = \"outer\", on=[\"Image directory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ba5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_merged.to_csv('results_reference_consolidated_hamming2.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
